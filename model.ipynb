{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "\n",
    "import copy\n",
    "\n",
    "torch.set_printoptions(threshold=float('inf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('chr19.npz', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Dataset Class\n",
    "## Notice that the __init__ method contains an argument `apply_log10`, if you set it to True\n",
    "## you will apply a log10 to the raw counts. We can experiment with this\n",
    "class MethDataset(Dataset):\n",
    "    def __init__(self, sequence, histone, methylation, coords, apply_log10=False):\n",
    "        self.sequence = sequence\n",
    "        self.histone = histone\n",
    "        self.methylation = methylation\n",
    "        self.transform = apply_log10\n",
    "        self.coords = coords\n",
    "        self.histone_names = ['H3K4me3', 'H3K36me2', 'H3K27me3', 'H3K9me3']\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.methylation.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        sequence = torch.from_numpy(self.sequence[idx])\n",
    "        histone = self.histone.astype(np.float32)\n",
    "\n",
    "        H3K4me3 = torch.from_numpy(histone[:, :, 0][idx].astype(np.float32)) if not self.transform else torch.from_numpy(np.log10(histone[:, :, 0]+1e-4)[idx])\n",
    "        H3K36me2 = torch.from_numpy(histone[:, :, 1][idx].astype(np.float32)) if not self.transform else torch.from_numpy(np.log10(histone[:, :, 1]+1e-4)[idx])\n",
    "        H3K27me3 = torch.from_numpy(histone[:, :, 2][idx].astype(np.float32)) if not self.transform else torch.from_numpy(np.log10(histone[:, :, 2]+1e-4)[idx])\n",
    "        H3K9me3 = torch.from_numpy(histone[:, :, 3][idx].astype(np.float32)) if not self.transform else torch.from_numpy(np.log10(histone[:, :, 3]+1e-4)[idx])\n",
    "\n",
    "        methylation = self.methylation[idx]\n",
    "        coordinates = self.coords[idx]\n",
    "\n",
    "        return sequence, H3K4me3, H3K36me2, H3K27me3, H3K9me3, methylation, coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = data['dna'].shape[0]\n",
    "split_index = int(0.8 * size) ### 80% of the data will be for training\n",
    "\n",
    "# I'm applying log10 in both cases\n",
    "train_dataset = MethDataset(sequence = data['dna'][:split_index],\n",
    "                           histone = data['histone'][:split_index], \n",
    "                           methylation = data['methyl'][:split_index],\n",
    "                           coords = data['coords'][:split_index],\n",
    "                           apply_log10=True)\n",
    "\n",
    "test_dataset = MethDataset(sequence = data['dna'][split_index:],\n",
    "                           histone = data['histone'][split_index:], \n",
    "                           methylation = data['methyl'][split_index:],\n",
    "                           coords = data['coords'][split_index:],\n",
    "                           apply_log10=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model class\n",
    "## 1- My idea is to be able to control de architecture of the model, and training parameters since the model is created.\n",
    "## This should make it easier to debug and to try different architectures, and the architecture of the model can be \n",
    "## specified through the arguments.\n",
    "## 2- The `forward` method unsqueezes the input so the model understands the structure in batches.\n",
    "## 3- There is a method called `training_loop`. Please, complete it, after you specify the architecture, add the loss function, and backward\n",
    "## propagation step\n",
    "## 4- I think we can add an `eval_loop` method, in which we iterate over the `test_dataloader` and evaluate the accuracy of the model (R^2)\n",
    "## 5- Try some architectures, and some way to pass arguments to the model, such that we can try different numbers without having problems\n",
    "## with tensor shapes and things like that. The idea is to be able to test certain combinations of numbers, so we can use Optuna to make\n",
    "## a bayesian search for \"optimal\" parameters. Look at papers where people use CNNs for DNA and histone marks, try to have a similar architecture\n",
    "## and let's start with that\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, DNA_kernel_sizes, DNA_strides, DNA_conv_channels,\n",
    "                    epochs=100, learning_rate=1e-3, optimizer=torch.optim.SGD):\n",
    "        super().__init__()\n",
    "        # Module parameters\n",
    "        self.DNA_layer1_kernel_size, self.DNA_layer2_kernel_size, self.DNA_layer3_kernel_size, self.DNA_layer4_kernel_size = DNA_kernel_sizes\n",
    "        self.DNA_conv_channels = DNA_conv_channels\n",
    "        self.DNA_layer1_stride, self.DNA_layer2_stride, self.DNA_layer3_stride, self.DNA_layer4_stride = DNA_strides\n",
    "\n",
    "        # Training parameters\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate=learning_rate\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "        # Modules and architecture\n",
    "        self.dna_module = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=4, out_channels=DNA_conv_channels, kernel_size=(self.DNA_layer1_kernel_size), \n",
    "                        stride=self.DNA_layer1_stride, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=(self.DNA_layer2_kernel_size), \n",
    "                        stride=self.DNA_layer2_stride, padding=0),\n",
    "            nn.Conv1d(in_channels=DNA_conv_channels, out_channels=1, kernel_size=(self.DNA_layer3_kernel_size), \n",
    "                        stride=self.DNA_layer3_stride, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=(self.DNA_layer4_kernel_size), \n",
    "                        stride=self.DNA_layer4_stride, padding=0)\n",
    "        )\n",
    "\n",
    "        self.histone_module = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=1, out_channels=1, kernel_size=(self.DNA_layer1_kernel_size), \n",
    "                        stride=self.DNA_layer1_stride, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=(self.DNA_layer2_kernel_size), \n",
    "                        stride=self.DNA_layer2_stride, padding=0),\n",
    "            nn.Conv1d(in_channels=1, out_channels=1, kernel_size=(self.DNA_layer3_kernel_size), \n",
    "                        stride=self.DNA_layer3_stride, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=(self.DNA_layer4_kernel_size), \n",
    "                        stride=self.DNA_layer4_stride, padding=0)\n",
    "        )\n",
    "\n",
    "        self.H3K4me3_module = self.histone_module\n",
    "        self.H3K36me2_module = self.histone_module\n",
    "        self.H3K27me3_module = self.histone_module\n",
    "        self.H3K9me3_module = self.histone_module\n",
    "\n",
    "\n",
    "        self.attn = nn.MultiheadAttention(embed_dim=5, num_heads=5, batch_first=True)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(5, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 10),\n",
    "            nn.Linear(10, 1),\n",
    "            nn.Softplus()\n",
    "        )\n",
    "\n",
    "    def forward(self, sequence, H3K4me3, H3K36me2, H3K27me3, H3K9me3, methylation):\n",
    "        sequence = sequence.to(torch.float32).permute(0, 2, 1) ### Changed to (B,C=4,L=500) to use Conv1D\n",
    "        dna_module_output = self.dna_module(sequence).reshape(-1, 1)\n",
    "\n",
    "        H3K4me3_module_output = self.H3K4me3_module(H3K4me3.unsqueeze(1)).reshape(-1, 1)\n",
    "        H3K36me2_module_output = self.H3K36me2_module(H3K36me2.unsqueeze(1)).reshape(-1, 1)\n",
    "        H3K27me3_module_output = self.H3K27me3_module(H3K27me3.unsqueeze(1)).reshape(-1, 1)\n",
    "        H3K9me3_module_output = self.H3K9me3_module(H3K9me3.unsqueeze(1)).reshape(-1, 1)\n",
    "        \n",
    "        # stack = torch.stack([dna_module_output, H3K4me3_module_output, H3K36me2_module_output, H3K27me3_module_output, H3K9me3_module_output]).permute(1,0,2) # Not sure if this is ok\n",
    "        stack = torch.stack([dna_module_output, H3K4me3_module_output, H3K36me2_module_output, H3K27me3_module_output, H3K9me3_module_output]).permute(1,0,2) # Not sure if this is ok\n",
    "        prediction = self.fc(stack.squeeze(2))\n",
    "        \n",
    "        return prediction\n",
    "\n",
    "\n",
    "    def training_loop(self, loss_fn, train_dataset, batch_size=10):\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        optimizer = self.optimizer(self.parameters(), lr=self.learning_rate)\n",
    "        loss_fn = loss_fn()\n",
    "\n",
    "        self.train()\n",
    "        for e in range(self.epochs):\n",
    "            for i, (sequence, H3K4me3, H3K36me2, H3K27me3, H3K9me3, methylation, coordinates) in enumerate(train_dataloader):\n",
    "                \n",
    "                prediction = self.forward(sequence, H3K4me3, H3K36me2, H3K27me3, H3K9me3, methylation)\n",
    "\n",
    "                loss = loss_fn(prediction, methylation.unsqueeze(-1).to(torch.float32))\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "\n",
    "            if e % 50 == 0:\n",
    "                print(f\"Iter: {e+1}, Loss: {loss.item()}\")\n",
    "    \n",
    "    def eval_loop(args, kwargs):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(DNA_kernel_sizes=(25,5,5,3), DNA_strides=(5,5,5,1), DNA_conv_channels = 2,\n",
    "                    epochs=150, learning_rate=1e-3, optimizer=torch.optim.Adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.training_loop(loss_fn=nn.MSELoss, train_dataset=train_dataset, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence, H3K4me3, H3K36me2, H3K27me3, H3K9me3, methylation, coordinates = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 500])\n",
      "torch.Size([8, 1, 500])\n"
     ]
    }
   ],
   "source": [
    "print(H3K4me3.shape)\n",
    "print(H3K4me3.unsqueeze(1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 0, 0,  ..., 0, 0, 1],\n",
       "         [0, 0, 0,  ..., 1, 1, 0],\n",
       "         [0, 0, 1,  ..., 0, 0, 0],\n",
       "         [0, 1, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 1,  ..., 1, 0, 1],\n",
       "         [0, 1, 0,  ..., 0, 1, 0],\n",
       "         [1, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[1, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 1, 1],\n",
       "         [0, 1, 1,  ..., 1, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 1, 1,  ..., 0, 1, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 1],\n",
       "         [0, 0, 0,  ..., 1, 0, 0]],\n",
       "\n",
       "        [[1, 0, 1,  ..., 1, 0, 1],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 1, 0,  ..., 0, 1, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 1,  ..., 0, 0, 0],\n",
       "         [0, 1, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 1],\n",
       "         [1, 0, 0,  ..., 1, 1, 0]]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq[0].shape    # [8, 500, 4] I need to reshape this to (B,C=4,L=500)\n",
    "seq[0].permute(0,2, 1)    # [8, 500, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0,  ..., 0, 0, 1],\n",
       "        [0, 0, 0,  ..., 1, 1, 0],\n",
       "        [0, 0, 1,  ..., 0, 0, 0],\n",
       "        [0, 1, 0,  ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq[0][0].transpose(-2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0,  ..., 0, 0, 1],\n",
       "        [0, 0, 0,  ..., 1, 1, 0],\n",
       "        [0, 0, 1,  ..., 0, 0, 0],\n",
       "        [0, 1, 0,  ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq[0].permute(0, 2, 1)[0]#.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m nn\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[0;32m----> 2\u001b[0m             nn\u001b[38;5;241m.\u001b[39mConv1d(in_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, out_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mDNA_layer1_kernel_height, \u001b[38;5;241m4\u001b[39m), \n\u001b[1;32m      3\u001b[0m                         stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mDNA_layer1_stride, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mDNA_layer1_padding)\n\u001b[1;32m      4\u001b[0m         )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "[\n",
    "    [[1,\n",
    "      0,\n",
    "      0,\n",
    "      1]\n",
    "     ],\n",
    "     [[0,0,1,0],\n",
    "      [0,0,0,0],\n",
    "      [0,0,0,0],\n",
    "      [0,0,1,0]],\n",
    "     [],\n",
    "     [],CHANNEL4], BATCH1\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    " ]\n",
    " BATCH=5, CHANNEL=4, WIDTH=, HEIGHT="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_out_Conv1D(length, kernel_size,\n",
    "                  padding, stride, dilation=1):\n",
    "    return np.floor((length+2*padding-dilation*(kernel_size-1)-1)/stride+1).astype(int)\n",
    "\n",
    "def get_out_MaxPool1D(length, kernel_size,\n",
    "                  padding, stride, dilation=1):\n",
    "    return np.floor((length+2*padding-dilation*(kernel_size-1)-1)/stride+1).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "k1=25\n",
    "s1=5\n",
    "\n",
    "k2=5\n",
    "s2=5\n",
    "\n",
    "k3=5\n",
    "s3=5\n",
    "\n",
    "k4=3\n",
    "s4=1\n",
    "\n",
    "size1 = get_out_Conv1D(length=500, kernel_size=k1, padding=0, stride=s1)\n",
    "size2 = get_out_MaxPool1D(length=size1, kernel_size=k2 ,padding=0, stride=s2, dilation=1)\n",
    "size3 = get_out_Conv1D(length=size2, kernel_size=k3, padding=0, stride=s3)\n",
    "size4 = get_out_MaxPool1D(length=size3, kernel_size=k4, padding=0, stride=s4, dilation=1)\n",
    "\n",
    "\n",
    "print(size4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 18)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2, h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "optim = torch.optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GPyOpt check this library (== Optuna)\n",
    "\n",
    "### Model from \n",
    "\n",
    "# def d_cnn_model(input_length):\n",
    "#     model = Sequential()\n",
    "\n",
    "#     model.add(Dropout(0.2, input_shape=(input_length,1)))\n",
    "#     model.add(Conv1D(32, 3, activation='relu'))\n",
    "#     # model.add(Conv1D(32, 3, activation='relu'))\n",
    "#     # model.add(Dropout(0.5))\n",
    "#     model.add(MaxPooling1D(2))\n",
    "\n",
    "#     model.add(Conv1D(64, 3, activation='relu'))\n",
    "#     # # model.add(Dropout(0.5))\n",
    "#     model.add(MaxPooling1D(2))\n",
    "\n",
    "#     model.add(Conv1D(128, 3, activation='relu'))\n",
    "#     # # model.add(Dropout(0.5))\n",
    "#     model.add(MaxPooling1D(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
